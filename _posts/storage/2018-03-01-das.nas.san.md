---
toc: true
toc_label: "DAS, NAS, SAN 简介"
toc_icon: "code"
title: "DAS, NAS, SAN 简介"
tags: das nas san iscsi
categories: "storage"
classes: wide
excerpt: "常见存储方案"
header:
  overlay_image: /assets/images/header/programming.jpg
  overlay_filter: rgba(0, 0, 0, 0.6)
---

{% include figure image_path="/assets/images/das.nas.san.png" alt="DAS NAS SAN 的本质区别" %}


## DAS

Direct Attached Storage

直连存储，是指将存储设备通过总线（SCSI、PCI、IDE 等）接口直接连接到一台计算机上。

DAS 购置成本低，配置简单，因此对于小型企业很有吸引力。在中小企业中，许多数据应用必须安装在直连的 DAS 存储器上。

{% include figure image_path="/assets/images/storage-das.png" alt="" %}

采用 DAS 的服务器结构，其外部数据存储设备采用 SCSI 或 FC（Fibre Channel）技术，直接挂接在 **内部总线** 上的方式，数据存储是整个服务器结构的一部分。

DAS 这种直连方式，能够解决单台服务器的存储空间扩展、高性能传输需求，并且单台外置存储系统的容量，已经从不到 1TB，发展到了 2TB，随着大容量硬盘的推出，单台外置存储系统容量还会上升。此外，DAS 还可以构成基于 RAID 的双机高可用系统，满足数据存储对高可用的要求。从趋势上看，作为一种存储模式，DAS 仍然会继续得到应用。

DAS 不算是网络存储，因为 **只能被挂载它的主机访问**。因此，服务器发生故障时，连接在服务器上的 DAS 存储设备中的数据暂时不能被存取。


### 适用场景

* 服务器在地理分布上很分散，很难用 SAN 或 NAS 互连，如商店或银行的分支。
* 存储系统必须直连到服务器，如数据库应用、邮件服务等。





### 缺点

#### 占用主机资源

DAS **依赖** 主机的 **操作系统** 进行数据的 IO 读写和存储维护管理。

数据备份操作复杂。

在数据备份和恢复过程中，数据需要先回流到主机，再传输到直连的磁带机上。会占用较多的主机资源，约为 20-30%。因此许多企业用户的日常数据备份常常在深夜或业务系统不繁忙时进行，以免影响正常业务系统的运行。直连式存储的数据量越大，备份和恢复的时间就越长，对服务器硬件的依赖性和影响就越大。

#### 扩展性差

服务器本身容易成为系统瓶颈。

DAS 与主机通常采用 **SAS**（Serial SCSI） 连接。随着 CPU 的处理能力越来越强，硬盘空间越来越大，阵列的硬盘数量越来越多，SAS 通道将会成为 IO 的瓶颈；主机的 **SCSI ID 资源有限**，能够建立的 SAS 通道连接有限。

#### 不支持高可用

服务器发生故障，数据不可访问。DAS 在扩展存储阵列容量时，会造成业务系统的停机，从而给企业带来经济损失。对于银行、电信、传媒等行业7×24小时服务的关键业务系统，这是不可接受的。并且直连式存储或服务器主机的升级扩展，只能由原设备厂商提供，往往受原设备厂商限制。

#### 无法动态分配存储空间

对于存在多个服务器的系统来说，设备分散，不便管理。同时多台服务器使用 DAS 时，存储空间不能在服务器之间动态分配，可能造成相当的资源浪费。



















## NAS

Network Attached Storage

网络连接存储，采用网络（TCP/IP、ATM、FDDI）技术，通过网络交换机连接存储系统和服务器主机，建立专用于数据存储的存储私网。

NAS 被定义为一种特殊的专用数据存储服务器，包括存储设备（磁盘阵列、光驱、磁带驱动器、便携存储介质等）和内置的系统软件，可提供 **跨平台文件共享** 功能。

NAS 通常在一个 LAN 上占有自己的节点，无需应用服务器的干预，允许用户在网络上存取数据，在这种配置中，NAS 集中管理和处理网络上的所有数据，将负载从应用或企业服务器上分离开来，有效降低总拥有成本，保护用户投资。

NAS 本身能够支持多种协议（如 NFS、CIFS、FTP、HTTP 等），而且能够支持各种操作系统。通过任何一台工作站，用浏览器就可以对 NAS 设备进行直观方便的管理。

NAS 是一种专用数据存储服务器。它以数据为中心，将存储设备与服务器彻底分离，集中管理数据，从而释放带宽、提高性能、降低总拥有成本、保护投资。其成本远远低于使用服务器存储，而效率却远远高于后者。目前国际著名的 NAS 企业有 Netapp、EMC、OUO 等。

NAS 是 **文件级** 的存储方法，它的重点在于帮助工作组和部门级机构解决迅速增加存储容量的需求。NAS 主要用于文件共享，例如需要共享大型 CAD 文档的工程小组。

{% include figure image_path="/assets/images/NAS-Diagram-932x523.gif" alt="" %}

NAS 是 **功能单一的精简型电脑**。NAS 在架构上与个人电脑相似，但因功能单纯，可移除许多不必要的连接器、控制晶片、电子回路，如键盘、鼠标、USB、VGA等。



### 优点

#### 即插即用

NAS 产品是真正 **即插即用** 的产品。NAS 设备一般支持 **多计算机平台**，用户通过网络支持协议可进入相同的文档，因而 NAS 设备无需改造即可用于混合 Unix/Windows 局域网内。

#### 不受物理位置限制

NAS 设备的物理位置可以很灵活，可放置在工作组内，靠近数据中心的应用服务器，也可放在其他地点，通过物理链路与网络连接起来。

#### 不占用主机资源

NAS 设备的目的就是为了 **分离** 网络设备中的服务器和存储。这样做能够让服务器（特别是通用服务器）有更多的计算资源来处理用户的各种应用和业务（如电子邮件处理、远程应用等）。NAS 则用来帮助服务器完成一些文件的任务和 I/O 的操作。

#### 高可扩展性

NAS 的扩展只需通过添加一个节点及网络设备即可，做到了真正的即插即用，并且部署位置非常灵活。基本上启动 NAS 设备，运行相应的网络文件系统，并将这个 NAS 设备接入网络环境就完成了添加。高级 NAS 更能做到支持网络接口的热安装、硬盘的的随时增加等。

当前 NAS 的扩展趋势已经演变成为 **NAS 集群** 技术了。NAS 集群技术通过一组 NAS 设备集合来形成如同一个 NAS 设备，NAS 集群技术提供了一定的 **存储分流**，使得不同的 NAS 设备可以同时工作，以满足网络存储需求，从而提高了整个 NAS 系统的整体性能，并解决了多个 NAS 系统的扩展性和管理趋于复杂性的问题。

#### 易于管理

NAS 本身就是为了企业内部网络而设计，实现了异构平台下的数据共享，因此 NAS 的使用和维护成本就相对很低，管理和维护工作也相对简单。用户只需一些简单的初期设置和管理，NAS 设备就可以很好的运行起来。





### 缺点

传统的 TCP/IP 协议不可避免的给 NAS 带来一些 “先天” 的缺点。

#### 存储性能的局限

NAS 虽然比传统的 DAS 设备在存储性能上有很大的提高，但是只适合较小的网络或局域网内。在 SAN 中，已经将备份数据流从 LAN 中转移了出去，而 NAS 却仍在使用网络进行备份和恢复。它将存储事务由并行 SCSI 连接转移到了网络上。这就是说，LAN 除了必须处理正常的最终用户传输流外，还必须处理包括备份操作的存储磁盘请求。

由于存储数据通过普通数据网络传输，因此易受网络上其它流量的影响。当网络上有其它大数据流量时会严重影响系统性能。当多台客户端访问 NAS 文件系统时，性能会大大的下降，最终不能满足用户的需求。

#### 数据安全

由于存储数据通过普通数据网络传输，因此容易产生数据泄漏等安全问题。

#### 可靠性有待提高

当企业内部网络发展到一定的规模时，NAS 设备的数据服务和数据管理形成了网络的双重负担，也就是说 NAS 除了要处理正常的终端数据 I/O 请求外，还需要做备份和恢复等操作。并且 NAS 后期的扩容成本高；一般的 NAS 没有高可用配置，容易形成单点故障。





















## SAN

Storage Area Network

存储区域网络，是一种连接外接存储设备和服务器的架构。采用光纤通道技术、磁盘阵列、磁带柜、光盘柜等来实现。

连接到服务器的存储设备，将被操作系统 **视为直接连接的存储设备**。

除针对大型企业的企业级存储方案外，2000 年之后，SAN 的价格和复杂度有所下降，越来越多的中小型企业也在逐步采用该项技术。

与 SAN 相比较，NAS 设备使用的是基于文件的通信协议，如 NFS、SMB、CIFS 等通信协议，它们被明确的定义为 **远程** 存储设备，计算机请求访问的是 **抽象文件** 的一段内容，而非对磁盘进行的块设备操作。

{% include figure image_path="/assets/images/san1.jpg" alt="" %}





### 网络类型

大多数 SAN 使用 **SCSI 接口** 进行服务器与磁盘驱动器设备之间的通信。但该总线拓扑结构不适用于网络环境，所以没有使用底层物理连接介质（如连接电缆），而是采用其它底层通信协议作为 **镜像层** 来实现网络连接：

光纤通道协议（FCP, Fibre Channel Protocol），最常见的通过光纤通道来映射SCSI的一种连接方式；
iSCSI，基于TCP/IP的SCSI映射；
HyperSCSI，基于以太网的SCSI映射；
ATA over Ethernet，基于以太网的ATA映射；
使用光纤通道连接的FICON,常见与大型机环境；
Fibre Channel over Ethernet（FCoE），基于以太网的FC协议；
iSCSI Extensions for RDMA（iSER），基于InfiniBand（IB）的iSCSI连接；
iFCP[1]或SANoIP[2]基于IP网络的光纤通道协议（FCP）。
